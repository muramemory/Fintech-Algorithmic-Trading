{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Frequency Trading Algorithm\n",
    "\n",
    "You have been tasked by the investment firm Renaissance High Frequency Trading (RHFT) to develop an automated trading strategy utilizing a combination of machine learning algorithms and high frequency algorithms. RHFT wants this new algorithm to be based on stock market data of the 30 stocks in the Dow Jones at the minute level and to conduct buys and sells every minute based on 1 min, 5 min, and 10 min Momentum. The CIO asked you to choose the Machine Learning Algorithm best suited for this task and wants you to execute the trades via Alpaca's API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import alpaca_trade_api as tradeapi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load .env enviroment variables\n",
    "# YOUR CODE HERE\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Set Alpaca API key and secret\n",
    "# YOUR CODE HERE\n",
    "\n",
    "ALPACA_API_KEY = os.getenv('ALPACA_API_KEY')\n",
    "ALPACA_SECRET_KEY = os.getenv('ALPACA_SECRET_KEY')\n",
    "base_url = 'https://paper-api.alpaca.markets'\n",
    "\n",
    "print(type(ALPACA_API_KEY))\n",
    "print(type(ALPACA_SECRET_KEY))\n",
    "print(type(base_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Alpaca API object, specifying use of the paper trading account:\n",
    "# YOUR CODE HERE\n",
    "\n",
    "api = tradeapi.REST(\n",
    "    ALPACA_API_KEY,\n",
    "    ALPACA_SECRET_KEY,\n",
    "    base_url,\n",
    "    api_version=\"v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account({   'account_blocked': False,\n",
      "    'account_number': 'PA32IVXERF1F',\n",
      "    'accrued_fees': '0',\n",
      "    'buying_power': '200000',\n",
      "    'cash': '100000',\n",
      "    'created_at': '2022-01-22T00:56:46.046436Z',\n",
      "    'crypto_status': 'ACTIVE',\n",
      "    'currency': 'USD',\n",
      "    'daytrade_count': 0,\n",
      "    'daytrading_buying_power': '0',\n",
      "    'equity': '100000',\n",
      "    'id': 'e3535156-a8cc-4e05-b336-0e8221a49d85',\n",
      "    'initial_margin': '0',\n",
      "    'last_equity': '100000',\n",
      "    'last_maintenance_margin': '0',\n",
      "    'long_market_value': '0',\n",
      "    'maintenance_margin': '0',\n",
      "    'multiplier': '2',\n",
      "    'non_marginable_buying_power': '0',\n",
      "    'pattern_day_trader': False,\n",
      "    'pending_transfer_in': '0',\n",
      "    'portfolio_value': '100000',\n",
      "    'regt_buying_power': '200000',\n",
      "    'short_market_value': '0',\n",
      "    'shorting_enabled': True,\n",
      "    'sma': '100000',\n",
      "    'status': 'ACTIVE',\n",
      "    'trade_suspended_by_user': False,\n",
      "    'trading_blocked': False,\n",
      "    'transfers_blocked': False})\n"
     ]
    }
   ],
   "source": [
    "# obtain account information\n",
    "account = api.get_account()\n",
    "print(account)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Train and Compare Multiple Machine Learning Algorithms\n",
    "\n",
    " In this section, you'll train each of the requested algorithms and compare performance. Be sure to use the same parameters and training steps for each model. This is necessary to compare each model accurately.\n",
    "\n",
    "### Preprocessing Data\n",
    "\n",
    "#### 1. Generate your feature data (`X`) and target data (`y`):\n",
    "* Create a dataframe `X` that contains all the columns from the returns dataframe that will be used to predict `F_1_m_returns`.\n",
    "* Create a variable, called `y`, that is equal 1 if `F_1_m_returns` is larger than 0. This will be our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset returns.csv and set the index to level_0 and time\n",
    "# YOUR CODE HERE\n",
    "\n",
    "returns_path = Path(\"returns.csv\")\n",
    "returns_df = pd.read_csv(returns_path)\n",
    "returns_df1 = returns_df.set_index('level_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_1</th>\n",
       "      <th>F_1_m_returns</th>\n",
       "      <th>1_m_returns</th>\n",
       "      <th>5_m_returns</th>\n",
       "      <th>10_m_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>2021-01-05 09:40:00-05:00</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.004758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>2021-01-05 09:41:00-05:00</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>0.004941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>2021-01-05 09:42:00-05:00</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.003782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>2021-01-05 09:43:00-05:00</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>0.007850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>2021-01-05 09:44:00-05:00</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.005416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>2021-01-05 15:55:00-05:00</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.000164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>2021-01-05 15:56:00-05:00</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>2021-01-05 15:57:00-05:00</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>0.003868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>2021-01-05 15:58:00-05:00</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>0.004140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>2021-01-05 15:59:00-05:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.004934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2660 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           level_1  F_1_m_returns  1_m_returns  5_m_returns  \\\n",
       "level_0                                                                       \n",
       "FB       2021-01-05 09:40:00-05:00       0.000814     0.000074     0.001260   \n",
       "FB       2021-01-05 09:41:00-05:00       0.000887     0.000814     0.001889   \n",
       "FB       2021-01-05 09:42:00-05:00       0.000628     0.000887     0.001999   \n",
       "FB       2021-01-05 09:43:00-05:00       0.000480     0.000628     0.003408   \n",
       "FB       2021-01-05 09:44:00-05:00      -0.001291     0.000480     0.002886   \n",
       "...                            ...            ...          ...          ...   \n",
       "TSLA     2021-01-05 15:55:00-05:00      -0.000259     0.000437     0.001140   \n",
       "TSLA     2021-01-05 15:56:00-05:00       0.002033    -0.000259     0.000382   \n",
       "TSLA     2021-01-05 15:57:00-05:00       0.000463     0.002033     0.003463   \n",
       "TSLA     2021-01-05 15:58:00-05:00       0.000680     0.000463     0.004223   \n",
       "TSLA     2021-01-05 15:59:00-05:00       0.000000     0.000680     0.003357   \n",
       "\n",
       "         10_m_returns  \n",
       "level_0                \n",
       "FB           0.004758  \n",
       "FB           0.004941  \n",
       "FB           0.003782  \n",
       "FB           0.007850  \n",
       "FB           0.005416  \n",
       "...               ...  \n",
       "TSLA         0.000164  \n",
       "TSLA         0.000806  \n",
       "TSLA         0.003868  \n",
       "TSLA         0.004140  \n",
       "TSLA         0.004934  \n",
       "\n",
       "[2660 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_1_m_returns</th>\n",
       "      <th>1_m_returns</th>\n",
       "      <th>5_m_returns</th>\n",
       "      <th>10_m_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.004758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>0.004941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.003782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>0.007850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>-0.001291</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.005416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         F_1_m_returns  1_m_returns  5_m_returns  10_m_returns\n",
       "level_0                                                       \n",
       "FB            0.000814     0.000074     0.001260      0.004758\n",
       "FB            0.000887     0.000814     0.001889      0.004941\n",
       "FB            0.000628     0.000887     0.001999      0.003782\n",
       "FB            0.000480     0.000628     0.003408      0.007850\n",
       "FB           -0.001291     0.000480     0.002886      0.005416"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a separate dataframe for features and define the target variable as a binary target\n",
    "# YOUR CODE HERE\n",
    "X = returns_df1[['F_1_m_returns','1_m_returns','5_m_returns','10_m_returns']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_1</th>\n",
       "      <th>F_1_m_returns</th>\n",
       "      <th>1_m_returns</th>\n",
       "      <th>5_m_returns</th>\n",
       "      <th>10_m_returns</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>2021-01-05 09:40:00-05:00</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.004758</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>2021-01-05 09:41:00-05:00</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>0.004941</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>2021-01-05 09:42:00-05:00</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>2021-01-05 09:43:00-05:00</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>0.007850</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>2021-01-05 09:44:00-05:00</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>2021-01-05 15:55:00-05:00</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>2021-01-05 15:56:00-05:00</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>2021-01-05 15:57:00-05:00</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>2021-01-05 15:58:00-05:00</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>0.004140</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>2021-01-05 15:59:00-05:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.004934</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2660 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           level_1  F_1_m_returns  1_m_returns  5_m_returns  \\\n",
       "level_0                                                                       \n",
       "FB       2021-01-05 09:40:00-05:00       0.000814     0.000074     0.001260   \n",
       "FB       2021-01-05 09:41:00-05:00       0.000887     0.000814     0.001889   \n",
       "FB       2021-01-05 09:42:00-05:00       0.000628     0.000887     0.001999   \n",
       "FB       2021-01-05 09:43:00-05:00       0.000480     0.000628     0.003408   \n",
       "FB       2021-01-05 09:44:00-05:00      -0.001291     0.000480     0.002886   \n",
       "...                            ...            ...          ...          ...   \n",
       "TSLA     2021-01-05 15:55:00-05:00      -0.000259     0.000437     0.001140   \n",
       "TSLA     2021-01-05 15:56:00-05:00       0.002033    -0.000259     0.000382   \n",
       "TSLA     2021-01-05 15:57:00-05:00       0.000463     0.002033     0.003463   \n",
       "TSLA     2021-01-05 15:58:00-05:00       0.000680     0.000463     0.004223   \n",
       "TSLA     2021-01-05 15:59:00-05:00       0.000000     0.000680     0.003357   \n",
       "\n",
       "         10_m_returns  signal  \n",
       "level_0                        \n",
       "FB           0.004758     1.0  \n",
       "FB           0.004941     1.0  \n",
       "FB           0.003782     1.0  \n",
       "FB           0.007850     1.0  \n",
       "FB           0.005416     0.0  \n",
       "...               ...     ...  \n",
       "TSLA         0.000164     0.0  \n",
       "TSLA         0.000806     1.0  \n",
       "TSLA         0.003868     1.0  \n",
       "TSLA         0.004140     1.0  \n",
       "TSLA         0.004934     1.0  \n",
       "\n",
       "[2660 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the target variable\n",
    "# YOUR CODE HERE\n",
    "\n",
    "returns_df1[\"signal\"] = 0.0\n",
    "returns_df1.loc[(returns_df1[\"F_1_m_returns\"] >= 0), \"signal\"] = 1\n",
    "returns_df1.loc[(returns_df1[\"F_1_m_returns\"] < 0), \"signal\"] = 0\n",
    "returns_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         signal\n",
       "level_0        \n",
       "FB          1.0\n",
       "FB          1.0\n",
       "FB          1.0\n",
       "FB          1.0\n",
       "FB          0.0\n",
       "FB          0.0\n",
       "FB          0.0\n",
       "FB          1.0\n",
       "FB          1.0\n",
       "FB          1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = returns_df1[['signal']]\n",
    "y.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note:\n",
    "> Notice that we don't use shuffle when splitting the dataset into a training and testing dataset. \n",
    "\n",
    "> We want to keep the original ordering of the data, so we don't end up using observations in the future to predict past observations,\n",
    "\n",
    "> This is a critical mistake known as look ahead bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use the train_test_split library to split the dataset into a training and testing dataset, with 70% used for testing\n",
    "* Set the shuffle parameter to False, so that you use the first 70% for training to prvent look ahead bias.\n",
    "* Make sure you have these 4 variables: `X_train`, `X_test`, `y_train`, `y_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset without shuffling\n",
    "# YOUR CODE HERE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use the `Counter` function to test the distribution of the data. \n",
    "* The result of `Counter({1: 668, 0: 1194})` reveals the data is indeed unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "signal\n",
       "1.0       1251\n",
       "0.0        744\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Counter function from the collections library\n",
    "from collections import Counter\n",
    "\n",
    "# Use Counter to count the number 1s and 0 in y_train\n",
    "# YOUR CODE HERE\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Balance the dataset with the Oversampler libary, setting `random state= 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomOverSampler from the imblearn library\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Use RandomOverSampler to resample the datase using random_state=1\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Test the distribution once again with `Counter`. The new result of `Counter({1: 1194, 0: 1194})` shows the data is now balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "signal\n",
       "0.0       1251\n",
       "1.0       1251\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Counter again to verify imbalance removed\n",
    "# YOUR CODE HERE\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "#### 1. The first cells in this section provide an example of how to fit and train your model using the `LogisticRegression` model from sklearn:\n",
    "* Import select model.\n",
    "* Instantiate model object.\n",
    "* Fit the model to the resampled data - `X_resampled` and `y_resampled`.\n",
    "* Predict the model using `X_test`.\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classification_report from sklearn\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7782    0.7427    0.7600       307\n",
      "         1.0     0.7876    0.8184    0.8027       358\n",
      "\n",
      "    accuracy                         0.7835       665\n",
      "   macro avg     0.7829    0.7806    0.7814       665\n",
      "weighted avg     0.7833    0.7835    0.7830       665\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\anaconda3\\envs\\algotrading\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Import LogisticRegression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a LogisticRegression model and train it on the X_resampled data we created before\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_resampled, y_resampled)  \n",
    "\n",
    "# Use the model you trained to predict using X_test\n",
    "y_pred = log_model.predict(X_test)   \n",
    "\n",
    "# Print out a classification report toevaluate performance\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use the same approach as above to train and test the following ML Algorithms:\n",
    "* [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "* [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
    "* [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
    "* [XGBClassifier](https://xgboost.readthedocs.io/en/latest/python/python_api.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\anaconda3\\envs\\algotrading\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       307\n",
      "         1.0       1.00      1.00      1.00       358\n",
      "\n",
      "    accuracy                           1.00       665\n",
      "   macro avg       1.00      1.00      1.00       665\n",
      "weighted avg       1.00      1.00      1.00       665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import RandomForestClassifier from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a RandomForestClassifier model and train it on the X_resampled data we created before\n",
    "# YOUR CODE HERE\n",
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=78)\n",
    "rf_model = rf_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Use the model you trained to predict using X_test\n",
    "# YOUR CODE HERE  \n",
    "predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Print out a classification report to evaluate performance\n",
    "# YOUR CODE HERE\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\anaconda3\\envs\\algotrading\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\antho\\anaconda3\\envs\\algotrading\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       307\n",
      "         1.0       1.00      1.00      1.00       358\n",
      "\n",
      "    accuracy                           1.00       665\n",
      "   macro avg       1.00      1.00      1.00       665\n",
      "weighted avg       1.00      1.00      1.00       665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import RandomForestClassifier from sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create a GradientBoostingClassifier model and train it on the X_resampled data we created before\n",
    "# YOUR CODE HERE\n",
    "\n",
    "model_gbc = GradientBoostingClassifier(n_estimators=500, learning_rate=1.0, \n",
    "                                 max_depth=1, random_state=0).fit(X_resampled, y_resampled)\n",
    "\n",
    "model_gbc.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Use the model you trained to predict using X_test\n",
    "# YOUR CODE HERE     \n",
    "\n",
    "predictions_gbc = model_gbc.predict(X_test)\n",
    "\n",
    "# Print out a classification report to evaluate performance\n",
    "# YOUR CODE HERE\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions_gbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       307\n",
      "         1.0       1.00      1.00      1.00       358\n",
      "\n",
      "    accuracy                           1.00       665\n",
      "   macro avg       1.00      1.00      1.00       665\n",
      "weighted avg       1.00      1.00      1.00       665\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\anaconda3\\envs\\algotrading\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Import RandomForestClassifier from sklearn\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Create a AdaBoostClassifier model and train it on the X_resampled data we created before\n",
    "# YOUR CODE HERE\n",
    "\n",
    "model_ada = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "model_ada.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Use the model you trained to predict using X_test\n",
    "# YOUR CODE HERE\n",
    "\n",
    "predictions_ada = model_ada.predict(X_test)\n",
    "\n",
    "# Print out a classification report to evaluate performance\n",
    "# YOUR CODE HERE\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:49:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       307\n",
      "         1.0       1.00      1.00      1.00       358\n",
      "\n",
      "    accuracy                           1.00       665\n",
      "   macro avg       1.00      1.00      1.00       665\n",
      "weighted avg       1.00      1.00      1.00       665\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\anaconda3\\envs\\algotrading\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\antho\\anaconda3\\envs\\algotrading\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\antho\\anaconda3\\envs\\algotrading\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Import RandomForestClassifier from sklearn\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create a XGBClassifier model and train it on the X_resampled data we created before\n",
    "# YOUR CODE HERE\n",
    "\n",
    "model_xgb =  XGBClassifier(n_estimators=100, random_state=0)\n",
    "model_xgb.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Use the model you trained to predict using X_test\n",
    "# YOUR CODE HERE\n",
    "predictions_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "# Print out a classification report to evaluate performance\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       307\n",
      "         1.0       1.00      1.00      1.00       358\n",
      "\n",
      "    accuracy                           1.00       665\n",
      "   macro avg       1.00      1.00      1.00       665\n",
      "weighted avg       1.00      1.00      1.00       665\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\anaconda3\\envs\\algotrading\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Import RandomForestClassifier from sklearn\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Create a AdaBoostClassifier model and train it on the X_resampled data we created before\n",
    "# YOUR CODE HERE\n",
    "\n",
    "model_ada = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "model_ada.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Use the model you trained to predict using X_test\n",
    "# YOUR CODE HERE\n",
    "\n",
    "predictions_ada = model_ada.predict(X_test)\n",
    "\n",
    "# Print out a classification report to evaluate performance\n",
    "# YOUR CODE HERE\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the performance of each model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Using the classification report for each model, choose the model with the highest precision for use in your algo-trading program.\n",
    "#### 2. Save the selected model with the `joblib` libary to avoid retraining every time you wish to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['log_model.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the joblib library \n",
    "import joblib\n",
    "\n",
    "# Use the library to save the model that you want to use for trading\n",
    "joblib.dump(log_model, 'log_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Implement the strongest model using Apaca API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop the Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use the provided code to ping the Alpaca API and create the DataFrame needed to feed data into the model.\n",
    "   * This code will also store the correct feature data in `X` for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'FB'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\algotrading\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\algotrading\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\algotrading\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'FB'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21148/1984142833.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Fetch the closing prices of our tickers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mdf_closing_prices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"FB\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"FB\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"close\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mdf_closing_prices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"AMZN\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"AMZN\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"close\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mdf_closing_prices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"AAPL\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"AAPL\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"close\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\algotrading\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\algotrading\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'FB'"
     ]
    }
   ],
   "source": [
    "# Create the list of tickers\n",
    "\n",
    "ticker_list = ['FB','AMZN','AAPL','NFLX', 'GOOGL', 'MSFT', 'TSLA']\n",
    "# Define Dates\n",
    "\n",
    "beg_date = '2021-01-06'\n",
    "end_date = '2021-01-06'\n",
    "\n",
    "# Convert the date in a format the Alpaca API reqires\n",
    "start =  pd.Timestamp(f'{beg_date} 09:30:00-0400', tz='America/New_York').replace(hour=9, minute=30, second=0).astimezone('GMT').isoformat()[:-6]+'Z'\n",
    "end   =  pd.Timestamp(f'{end_date} 16:00:00-0400', tz='America/New_York').replace(hour=15, minute=0, second=0).astimezone('GMT').isoformat()[:-6]+'Z'\n",
    "timeframe='1Min'\n",
    "\n",
    "# Use iloc to get the last 10 mins every time we pull new data\n",
    "prices = api.get_bars(ticker_list, timeframe, start=start, end=end).df.iloc[-11:]\n",
    "prices.ffill(inplace=True)   \n",
    "\n",
    "# Create an empty DataFrame for closing prices\n",
    "df_closing_prices = pd.DataFrame()\n",
    "\n",
    "# Fetch the closing prices of our tickers\n",
    "df_closing_prices[\"FB\"] = prices[\"FB\"][\"close\"]\n",
    "df_closing_prices[\"AMZN\"] = prices[\"AMZN\"][\"close\"]\n",
    "df_closing_prices[\"AAPL\"] = prices[\"AAPL\"][\"close\"]\n",
    "df_closing_prices[\"NFLX\"] = prices[\"NFLX\"][\"close\"]\n",
    "df_closing_prices[\"GOOGL\"] = prices[\"GOOGL\"][\"close\"]\n",
    "df_closing_prices['MSFT'] = prices['MSFT'][\"close\"]\n",
    "df_closing_prices['TSLA'] = prices['TSLA'][\"close\"]\n",
    "\n",
    "print(df_closing_prices.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'FB'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\algotrading\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\algotrading\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\algotrading\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'FB'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21148/2186109248.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fetch the closing prices of our tickers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_closing_prices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"FB\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"FB\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"close\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf_closing_prices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"AMZN\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"AMZN\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"close\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_closing_prices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"AAPL\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"AAPL\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"close\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_closing_prices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"NFLX\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"NFLX\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"close\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\algotrading\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\algotrading\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'FB'"
     ]
    }
   ],
   "source": [
    "# Fetch the closing prices of our tickers\n",
    "df_closing_prices[\"FB\"] = prices[\"FB\"][\"close\"]\n",
    "df_closing_prices[\"AMZN\"] = prices[\"AMZN\"][\"close\"]\n",
    "df_closing_prices[\"AAPL\"] = prices[\"AAPL\"][\"close\"]\n",
    "df_closing_prices[\"NFLX\"] = prices[\"NFLX\"][\"close\"]\n",
    "df_closing_prices[\"GOOGL\"] = prices[\"GOOGL\"][\"close\"]\n",
    "df_closing_prices['MSFT'] = prices['MSFT'][\"close\"]\n",
    "df_closing_prices['TSLA'] = prices['TSLA'][\"close\"]\n",
    "\n",
    "print(df_closing_prices.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of momentums\n",
    "list_of_momentums = [1,5,10]\n",
    "\n",
    "for i in list_of_momentums:  \n",
    "    # Compute percentage change for each one of the momentums in the momentum list\n",
    "    returns_temp = df_closing_prices.pct_change(i)\n",
    "    # Unstack the returns \n",
    "    returns_temp = pd.DataFrame(returns_temp.unstack())\n",
    "    name = f'{i}_m_returns'\n",
    "    returns_temp.rename(columns={0: name}, inplace = True)\n",
    "    # Reset the index so we can merge based on index\n",
    "    returns_temp.reset_index(inplace = True)\n",
    "    # Merge newly computed returns with previously created returns\n",
    "    if i ==1:\n",
    "        returns = returns_temp\n",
    "    else:\n",
    "        returns = pd.merge(returns,returns_temp,left_on=['level_0', 'time'],right_on=['level_0', 'time'], how='left', suffixes=('_original', 'right'))\n",
    "\n",
    "# Drop nulls and set index\n",
    "returns.dropna(axis=0, how='any', inplace=True)\n",
    "returns.set_index(['level_0', 'time'], inplace=True)\n",
    "\n",
    "# Generate feature data and preview first 10 rows.\n",
    "X = returns\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Using `joblib`, load the chosen model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previously trained and saved model using joblib\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use the model file to make predicttions:\n",
    "* Use `predict` on `X` and save this as `y_pred`.\n",
    "* Convert `y_pred` to a DataFrame, setting the index to the index of `X`.\n",
    "* Rename the column 0 to 'buy', be sure to set `inplace =True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model file to predict on X\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Convert y_pred to a dataframe, set the index to the index of X\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Rename the column 0 to 'buy', be sure to set inplace =True\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Filter the stocks where 'buy' is equal to 1, saving the filter as `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the stocks where 'buy' is equal to 1\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Using the `y_pred` filter, create a dictionary called `buy_dict` and assign 'n' to each Ticker (key value) as a placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary from y_pred and assign a 'n' to each of them for now as a placeholder.\n",
    "buy_dict = dict.fromkeys(y_pred.index.get_level_values(0), 'n')\n",
    "buy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Obtain the total available equity in your account from the Alpaca API and store in a variable called `total_capital`. You will split the capital equally between all selected stocks per the CIO's request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the total available equity in our account from the  Alpaca API\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute capital per stock, divide equity in account by number of stocks\n",
    "# Use Alpaca API to pull the equity in the account\n",
    "if len(buy_dict) > 0:\n",
    "    capital_per_stock = float(total_capital)/ len(buy_dict)\n",
    "else:\n",
    "    capital_per_stock = 0\n",
    "print(f'Capital per stock: {capital_per_stock}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Use a for-loop to iterate through `buy_dict` to determine the number stocks you need to buy for each ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use for loop to iterate through dictionary of buys \n",
    "# Determine the number stocks we need to buy for each ticker\n",
    "for ticker in buy_dict:\n",
    "    try:\n",
    "        buy_dict[ticker] = int(capital_per_stock /int(prices[ticker].iloc[-1]['close']))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(buy_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Cancel all previous orders in the Alpaca API (so you don't buy more than intended) and sell all currently held stocks to close all positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel all previous orders in the Alpaca API\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Sell all currently held stocks to close all positions\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Iterate through `buy_dict` and send a buy order for each ticker with their corresponding number of shares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the longlist object and send a buy order for each ticker with a corresponding number of shares:\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automate the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Make a function called `trade()` that incorporates all of the steps above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all of the steps conducted above into the function trade\n",
    "def trade():\n",
    "\n",
    "    ticker_list = ['FB','AMZN','AAPL','NFLX', 'GOOGL', 'MSFT', 'TSLA']\n",
    "    # Notice that we remove the start and end variables since we want the latest prices.\n",
    "    timeframe='1Min'\n",
    "    # Use iloc to get the last 10 mins every time we pull new data\n",
    "    prices = api.get_barset(ticker_list, \"minute\").df.iloc[-11:]\n",
    "    prices.ffill(inplace=True)   \n",
    "\n",
    "    # Create and empty DataFrame for closing prices\n",
    "    df_closing_prices = pd.DataFrame()\n",
    "\n",
    "    # Fetch the closing prices of our tickers\n",
    "    df_closing_prices[\"FB\"] = prices[\"FB\"][\"close\"]\n",
    "    df_closing_prices[\"AMZN\"] = prices[\"AMZN\"][\"close\"]\n",
    "    df_closing_prices[\"AAPL\"] = prices[\"AAPL\"][\"close\"]\n",
    "    df_closing_prices[\"NFLX\"] = prices[\"NFLX\"][\"close\"]\n",
    "    df_closing_prices[\"GOOGL\"] = prices[\"GOOGL\"][\"close\"]\n",
    "    df_closing_prices['MSFT'] = prices['MSFT'][\"close\"]\n",
    "    df_closing_prices['TSLA'] = prices['TSLA'][\"close\"]\n",
    "    print(df_closing_prices.head())\n",
    "    \n",
    "    # Loop through momentums to build new DataFrame\n",
    "    list_of_momentums = [1,5,10]\n",
    "    for i in list_of_momentums:   \n",
    "        returns_temp = df_closing_prices.pct_change(i)\n",
    "        returns_temp = pd.DataFrame(returns_temp.unstack())\n",
    "        name = f'{i}_m_returns'\n",
    "        returns_temp.rename(columns={0: name}, inplace = True)\n",
    "        returns_temp.reset_index(inplace = True)\n",
    "        if i ==1:\n",
    "            returns = returns_temp\n",
    "        else:\n",
    "            returns = pd.merge(returns,returns_temp,left_on=['level_0', 'time'],right_on=['level_0', 'time'], how='left', suffixes=('_original', 'right'))\n",
    "\n",
    "    # Drop nulls and set index            \n",
    "    returns.dropna(axis=0, how='any', inplace=True)\n",
    "    returns.set_index(['level_0', 'time'], inplace=True)\n",
    "\n",
    "    # Preprocess data for model\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # Create the `buy_dict` object\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Split capital between stocks and determine buy or sell\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    \n",
    "    # Cancel pending orders and close positions\n",
    "    # YOUR CODE HERE\n",
    "   \n",
    "    \n",
    "    # Submit orders\n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Import Python's schedule module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python's schedule module \n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use the \"schedule\" module to automate the algorithm:\n",
    "* Clear the schedule with `.clear()`.\n",
    "* Define a schedule to run the trade function every minute at 5 seconds past the minute mark (e.g. `10:31:05`).\n",
    "* Use the Alpaca API to check whether the market is open.\n",
    "* Use run_pending() function inside schedule to execute the schedule you defined while the market is open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the schedule\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Define a schedule to run the trade function every minute at 5 seconds past the minute mark (e.g. 10:31:05)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Use the Alpaca API to check whether the market is open\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Use run_pending() function inside schedule to execute the schedule you defined as long as the market is open\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:algotrading]",
   "language": "python",
   "name": "conda-env-algotrading-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
